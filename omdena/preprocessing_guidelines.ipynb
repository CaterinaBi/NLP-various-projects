{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic pre-processing of textual dataset\n",
    "# For EDA and language model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook demonstrates basic pre-processing techniques using the `nltk` and `spaCy` libraries\n",
    "\n",
    "The task is done to prepare datasets of hate speech for use in the Omdena Aswan Local Chapter, 'Detecting Hateful and Offensive Language using NLP', in which I am cooperating and co-leading the pre-processing and EDA tasks with Vishu Kalier.\n",
    "\n",
    "Here, we will be using the convabuse (https://github.com/amandacurry/convabuse) dataset.\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "I shall complete the task by strictly following the guidelines outlined for the project. These are as follows.\n",
    "\n",
    "### File structure\n",
    "\n",
    "The output of the pre-processing has to be a `.cvs` file. The file has to be organised in 5 columns as follows: \n",
    "| corpus_name | raw_sentence | label | clean_sentence_training | clean_sentence_EDA | \n",
    "\n",
    "### Labels\n",
    "\n",
    "The labels will be:\n",
    "\n",
    "- '2' for RISKY sentences (eg., 'hateful' or 'abusive');\n",
    "- '1' for POTENTIALLY RISKY sentences (e.g., 'offensive)';\n",
    "- '0' for NON RISKY sentences.\n",
    "\n",
    "### Pre-processing\n",
    "\n",
    "The pre-processing for the 'clean_sentence_training' column involves the following steps:\n",
    "\n",
    "1- delete all rows containing null values;\n",
    "\n",
    "2- stopwords removal;\n",
    "\n",
    "3- removal of digits and words containing digits, punctuation and special characters, extra spaces, links;\n",
    "\n",
    "4- lemmatization (NO stemming at it can yield undesirable results).\n",
    "\n",
    "The case of the sentences shoudn't be changed as the distinction between lowercase and uppercase can be meaningful in this context. The pre-processing for the 'clean_sentence_EDA' involves all the steps above, plus the deletion of all emojis (if present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/caterinabonan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "# don't forget to install any library that you don't have in your workspace yet\n",
    "# make sure that the environment you're installing your libraries corresponds to the one you're using to compile your code\n",
    "# note that the downloads form nltk might take a while\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import the spaCy standard model for English\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# use the command 'python -m spacy download en_core_web_lg' if the model isn't already in your machine\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# note that downloading the model can tale some time\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# refer to the spaCy documentation if you're working on languages other than English\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_lg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=30'>31</a>\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=31'>32</a>\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=36'>37</a>\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=37'>38</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=38'>39</a>\u001b[0m     \u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=39'>40</a>\u001b[0m \n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=40'>41</a>\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=51'>52</a>\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=52'>53</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=53'>54</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=54'>55</a>\u001b[0m         name,\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=55'>56</a>\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=56'>57</a>\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=57'>58</a>\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=58'>59</a>\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=59'>60</a>\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m     <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/__init__.py?line=60'>61</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/util.py:439\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/util.py?line=436'>437</a>\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/util.py?line=437'>438</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/caterinabonan/miniforge3/envs/NLP/lib/python3.10/site-packages/spacy/util.py?line=438'>439</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "# import the spaCy standard model for English\n",
    "# use the command 'python -m spacy download en_core_web_lg' if the model isn't already in your machine\n",
    "# note that downloading the model can tale some time\n",
    "# refer to the spaCy documentation if you're working on languages other than English\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86542dfcd30dcaa99d84c6e4d33cb0a4033de368badbca79a096b5e59f3a5c85"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
