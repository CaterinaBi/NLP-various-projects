{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic pre-processing of textual dataset\n",
    "# For EDA and language model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook demonstrates basic pre-processing techniques using the `nltk` and `spaCy` libraries\n",
    "\n",
    "The task is done to prepare datasets of hate speech for use in the Omdena Aswan Local Chapter, 'Detecting Hateful and Offensive Language using NLP', in which I am cooperating and co-leading the pre-processing and EDA tasks with Vishu Kalier.\n",
    "\n",
    "Here, we will be using the hatecheck-data (https://github.com/paul-rottger/hatecheck-data) dataset.\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "I shall complete the task by strictly following the guidelines outlined for the project. These are as follows.\n",
    "\n",
    "### File structure\n",
    "\n",
    "The output of the pre-processing has to be a `.cvs` file. The file has to be organised in 5 columns as follows: \n",
    "| corpus_name | raw_sentence | label | clean_sentence_training | clean_sentence_EDA | \n",
    "\n",
    "### Labels\n",
    "\n",
    "The labels will be:\n",
    "\n",
    "- '2' for RISKY sentences (eg., 'hateful' or 'abusive');\n",
    "- '1' for POTENTIALLY RISKY sentences (e.g., 'offensive)';\n",
    "- '0' for NON RISKY sentences.\n",
    "\n",
    "### Pre-processing\n",
    "\n",
    "The pre-processing for the 'clean_sentence_training' column involves the following steps:\n",
    "\n",
    "1- delete all rows containing null values;\n",
    "\n",
    "2- stopwords removal;\n",
    "\n",
    "3- removal of digits and words containing digits, punctuation and special characters, extra spaces, links;\n",
    "\n",
    "4- lemmatization (NO stemming at it can yield undesirable results).\n",
    "\n",
    "The case of the sentences shoudn't be changed as the distinction between lowercase and uppercase can be meaningful in this context. The pre-processing for the 'clean_sentence_EDA' involves all the steps above, plus the deletion of all emojis (if present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/caterinabonan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "# don't forget to install any library that you don't have in your workspace yet\n",
    "# make sure that the environment you're installing your libraries corresponds to the one you're using to compile your code\n",
    "# note that the downloads form nltk might take a while\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the spaCy standard model for English\n",
    "# use the command 'python -m spacy download en_core_web_lg' if the model isn't already in your machine\n",
    "# note that downloading the model can tale some time\n",
    "# refer to the spaCy documentation if you're working on languages other than English\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>functionality</th>\n",
       "      <th>case_id</th>\n",
       "      <th>templ_id</th>\n",
       "      <th>test_case</th>\n",
       "      <th>label_gold</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "      <th>label_5</th>\n",
       "      <th>label_6</th>\n",
       "      <th>label_7</th>\n",
       "      <th>label_8</th>\n",
       "      <th>label_9</th>\n",
       "      <th>label_10</th>\n",
       "      <th>count_label_h</th>\n",
       "      <th>count_label_nh</th>\n",
       "      <th>label_annot_maj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>2257</td>\n",
       "      <td>ident_neutral_nh</td>\n",
       "      <td>2258</td>\n",
       "      <td>488</td>\n",
       "      <td>Are there any disabled people on your course?</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>2522</td>\n",
       "      <td>ident_pos_nh</td>\n",
       "      <td>2523</td>\n",
       "      <td>526</td>\n",
       "      <td>I'll cherish any black person like you.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>1327</td>\n",
       "      <td>profanity_nh</td>\n",
       "      <td>1328</td>\n",
       "      <td>318</td>\n",
       "      <td>He gave me some bullshit excuse.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431</th>\n",
       "      <td>3431</td>\n",
       "      <td>spell_space_del_h</td>\n",
       "      <td>3432</td>\n",
       "      <td>814</td>\n",
       "      <td>You are nothing but common femaletrash.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>1202</td>\n",
       "      <td>profanity_h</td>\n",
       "      <td>1203</td>\n",
       "      <td>252</td>\n",
       "      <td>Typical of a trans person to be such a total s...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>384</td>\n",
       "      <td>derog_dehum_h</td>\n",
       "      <td>385</td>\n",
       "      <td>55</td>\n",
       "      <td>Immigrants are just a waste of space.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>3236</td>\n",
       "      <td>spell_char_swap_h</td>\n",
       "      <td>3237</td>\n",
       "      <td>786</td>\n",
       "      <td>If the idea comes from a trans person, it must...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>988</td>\n",
       "      <td>slur_h</td>\n",
       "      <td>989</td>\n",
       "      <td>129</td>\n",
       "      <td>Shemales just can't help themselves.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>1296</td>\n",
       "      <td>profanity_nh</td>\n",
       "      <td>1297</td>\n",
       "      <td>287</td>\n",
       "      <td>The theatre usher just told me to shut the fuc...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>3742</td>\n",
       "      <td>spell_leet_h</td>\n",
       "      <td>3743</td>\n",
       "      <td>849</td>\n",
       "      <td>W0men are the absolute worst.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      functionality  case_id  templ_id  \\\n",
       "2257        2257   ident_neutral_nh     2258       488   \n",
       "2522        2522       ident_pos_nh     2523       526   \n",
       "1327        1327       profanity_nh     1328       318   \n",
       "3431        3431  spell_space_del_h     3432       814   \n",
       "1202        1202        profanity_h     1203       252   \n",
       "384          384      derog_dehum_h      385        55   \n",
       "3236        3236  spell_char_swap_h     3237       786   \n",
       "988          988             slur_h      989       129   \n",
       "1296        1296       profanity_nh     1297       287   \n",
       "3742        3742       spell_leet_h     3743       849   \n",
       "\n",
       "                                              test_case   label_gold  \\\n",
       "2257      Are there any disabled people on your course?  non-hateful   \n",
       "2522           I'll cherish any black person like you.   non-hateful   \n",
       "1327                  He gave me some bullshit excuse.   non-hateful   \n",
       "3431           You are nothing but common femaletrash.       hateful   \n",
       "1202  Typical of a trans person to be such a total s...      hateful   \n",
       "384              Immigrants are just a waste of space.       hateful   \n",
       "3236  If the idea comes from a trans person, it must...      hateful   \n",
       "988               Shemales just can't help themselves.       hateful   \n",
       "1296  The theatre usher just told me to shut the fuc...  non-hateful   \n",
       "3742                     W0men are the absolute worst.       hateful   \n",
       "\n",
       "          label_1      label_2      label_3      label_4      label_5  \\\n",
       "2257  non-hateful          NaN          NaN  non-hateful  non-hateful   \n",
       "2522          NaN          NaN          NaN          NaN          NaN   \n",
       "1327  non-hateful          NaN  non-hateful  non-hateful          NaN   \n",
       "3431          NaN          NaN          NaN          NaN          NaN   \n",
       "1202          NaN          NaN          NaN          NaN          NaN   \n",
       "384           NaN      hateful      hateful      hateful          NaN   \n",
       "3236      hateful      hateful      hateful      hateful          NaN   \n",
       "988       hateful          NaN      hateful      hateful      hateful   \n",
       "1296  non-hateful  non-hateful          NaN  non-hateful  non-hateful   \n",
       "3742          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "          label_6      label_7      label_8      label_9     label_10  \\\n",
       "2257          NaN  non-hateful  non-hateful          NaN          NaN   \n",
       "2522  non-hateful  non-hateful  non-hateful  non-hateful  non-hateful   \n",
       "1327          NaN  non-hateful          NaN          NaN  non-hateful   \n",
       "3431      hateful      hateful      hateful      hateful      hateful   \n",
       "1202      hateful      hateful      hateful      hateful      hateful   \n",
       "384       hateful          NaN          NaN          NaN      hateful   \n",
       "3236          NaN          NaN          NaN          NaN      hateful   \n",
       "988           NaN      hateful          NaN          NaN          NaN   \n",
       "1296          NaN          NaN  non-hateful          NaN          NaN   \n",
       "3742      hateful      hateful      hateful  non-hateful      hateful   \n",
       "\n",
       "      count_label_h  count_label_nh label_annot_maj  \n",
       "2257              0               5     non-hateful  \n",
       "2522              0               5     non-hateful  \n",
       "1327              0               5     non-hateful  \n",
       "3431              5               0         hateful  \n",
       "1202              5               0         hateful  \n",
       "384               5               0         hateful  \n",
       "3236              5               0         hateful  \n",
       "988               5               0         hateful  \n",
       "1296              0               5     non-hateful  \n",
       "3742              4               1         hateful  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retreive the chosen dataset\n",
    "# display 10 random rows of the chosen dataset\n",
    "# display dataset shape\n",
    "# beware: this notebook and the dataset you want to work on HAVE TO BE in the same directory\n",
    "\n",
    "data = pd.read_csv(\"all_annotations.csv\")\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3901, 19)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of columns and rows\n",
    "# we will need this later to create our new file for clean data\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create our new file\n",
    "# as per guidelines, the first column will have to contain the name of the dataset\n",
    "# we multiply that number for the total number of rows in the original dataset\n",
    "\n",
    "dataset_name = ['hatecheck-data'] * 3901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create a dataframe using pandas\n",
    "# the dataframe defines the first columns name as 'corpus_name', and the contents as dataset_name as defined above\n",
    "\n",
    "new_dataset = pd.DataFrame(dataset_name, columns=['corpus_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the remaining 4 columns\n",
    "# assign a value to the 4 columns \n",
    "# one column is assigned to the sentence column (test_case) from the original file\n",
    "# three columns are left empty because they will host our pre-processed sentences\n",
    "\n",
    "new_dataset['raw_sentence'] = data['test_case']\n",
    "new_dataset['label'] = \"\"\n",
    "new_dataset['clean_sentence_training'] = \"\"\n",
    "new_dataset['clean_sentence_EDA'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          corpus_name                                 raw_sentence label  \\\n",
       "0     hatecheck-data                               I hate women.          \n",
       "1     hatecheck-data                        I hate trans people.          \n",
       "2     hatecheck-data                          I hate gay people.          \n",
       "3     hatecheck-data                        I hate black people.          \n",
       "4     hatecheck-data                     I hate disabled people.          \n",
       "...              ...                                          ...   ...   \n",
       "3896  hatecheck-data       Gay people are all complete 4ssholes.          \n",
       "3897  hatecheck-data     Black people are all complete 4ssholes.          \n",
       "3898  hatecheck-data  Disabled people are all complete 4ssholes.          \n",
       "3899  hatecheck-data          Muslims are all complete 4ssholes.          \n",
       "3900  hatecheck-data       Immigrants are all complete 4ssholes.          \n",
       "\n",
       "     clean_sentence_training clean_sentence_EDA  \n",
       "0                                                \n",
       "1                                                \n",
       "2                                                \n",
       "3                                                \n",
       "4                                                \n",
       "...                      ...                ...  \n",
       "3896                                             \n",
       "3897                                             \n",
       "3898                                             \n",
       "3899                                             \n",
       "3900                                             \n",
       "\n",
       "[3901 rows x 5 columns]>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no row contains null values so there is no need to delete any\n",
    "# at this point, the dataframe only contains values for the dataset name (first colums)\n",
    "# we can double check our progress by using the .head method\n",
    "\n",
    "new_dataset.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us now populate the second column, that dedicated to labels\n",
    "# the original dataset has two labels: hateful, non-hateful\n",
    "# here, hateful=2, non-hateful=0"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86542dfcd30dcaa99d84c6e4d33cb0a4033de368badbca79a096b5e59f3a5c85"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
