{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic pre-processing of textual dataset\n",
    "# For EDA and language model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook demonstrates basic pre-processing techniques using the `nltk` and `spaCy` libraries\n",
    "\n",
    "The task is done to prepare datasets of hate speech for use in the Omdena Aswan Local Chapter, 'Detecting Hateful and Offensive Language using NLP', in which I am cooperating and co-leading the pre-processing and EDA tasks with Vishu Kalier.\n",
    "\n",
    "Here, we will be using the hatecheck-data (https://github.com/paul-rottger/hatecheck-data) dataset.\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "I shall complete the task by strictly following the guidelines outlined for the project. These are as follows.\n",
    "\n",
    "### File structure\n",
    "\n",
    "The output of the pre-processing has to be a `.cvs` file. The file has to be organised in 5 columns as follows: \n",
    "| corpus_name | raw_sentence | label | clean_sentence_training | clean_sentence_EDA | \n",
    "\n",
    "### Labels\n",
    "\n",
    "The labels will be:\n",
    "\n",
    "- '2' for RISKY sentences (eg., 'hateful' or 'abusive');\n",
    "- '1' for POTENTIALLY RISKY sentences (e.g., 'offensive)';\n",
    "- '0' for NON RISKY sentences.\n",
    "\n",
    "### Pre-processing\n",
    "\n",
    "The pre-processing for the 'clean_sentence_training' column involves the following steps:\n",
    "\n",
    "1- delete all rows containing null values;\n",
    "\n",
    "2- stopwords removal;\n",
    "\n",
    "3- removal of digits and words containing digits, punctuation and special characters, extra spaces, links;\n",
    "\n",
    "4- lemmatization (NO stemming at it can yield undesirable results).\n",
    "\n",
    "The case of the sentences shoudn't be changed as the distinction between lowercase and uppercase can be meaningful in this context. The pre-processing for the 'clean_sentence_EDA' involves all the steps above, plus the deletion of all emojis (if present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "# don't forget to install any library that you don't have in your workspace yet\n",
    "# make sure that the environment you're installing your libraries corresponds to the one you're using to compile your code\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the spaCy standard model for English\n",
    "# use the command 'python -m spacy download en_core_web_lg' if the model isn't already in your machine\n",
    "# note that downloading the model can tale some time\n",
    "# refer to the spaCy documentation if you're working on languages other than English\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>functionality</th>\n",
       "      <th>case_id</th>\n",
       "      <th>templ_id</th>\n",
       "      <th>test_case</th>\n",
       "      <th>label_gold</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "      <th>label_5</th>\n",
       "      <th>label_6</th>\n",
       "      <th>label_7</th>\n",
       "      <th>label_8</th>\n",
       "      <th>label_9</th>\n",
       "      <th>label_10</th>\n",
       "      <th>count_label_h</th>\n",
       "      <th>count_label_nh</th>\n",
       "      <th>label_annot_maj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1475</td>\n",
       "      <td>ref_subs_clause_h</td>\n",
       "      <td>1476</td>\n",
       "      <td>376</td>\n",
       "      <td>If immigrants like you refuse to fit in, they ...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2013</td>\n",
       "      <td>phrase_question_h</td>\n",
       "      <td>2014</td>\n",
       "      <td>453</td>\n",
       "      <td>What if we just killed all Muslims?</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>2778</td>\n",
       "      <td>counter_ref_nh</td>\n",
       "      <td>2779</td>\n",
       "      <td>558</td>\n",
       "      <td>Do you not realise how hateful you are being w...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1306</td>\n",
       "      <td>profanity_nh</td>\n",
       "      <td>1307</td>\n",
       "      <td>297</td>\n",
       "      <td>Motherfucker, how is that even possible?</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1397</td>\n",
       "      <td>ref_subs_clause_h</td>\n",
       "      <td>1398</td>\n",
       "      <td>365</td>\n",
       "      <td>I don't have anything against Muslims but most...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>2309</td>\n",
       "      <td>ident_neutral_nh</td>\n",
       "      <td>2310</td>\n",
       "      <td>496</td>\n",
       "      <td>We have never had a female president.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>1644</td>\n",
       "      <td>ref_subs_sent_h</td>\n",
       "      <td>1645</td>\n",
       "      <td>401</td>\n",
       "      <td>We're talking about women here. They can't hel...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>1532</td>\n",
       "      <td>ref_subs_sent_h</td>\n",
       "      <td>1533</td>\n",
       "      <td>385</td>\n",
       "      <td>That's typical of women. They're absolutely de...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>452</td>\n",
       "      <td>derog_impl_h</td>\n",
       "      <td>453</td>\n",
       "      <td>65</td>\n",
       "      <td>Disabled people should be dumped in a landfill.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>3435</td>\n",
       "      <td>spell_space_del_h</td>\n",
       "      <td>3436</td>\n",
       "      <td>814</td>\n",
       "      <td>You are nothing but common disabledtrash.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      functionality  case_id  templ_id  \\\n",
       "1475        1475  ref_subs_clause_h     1476       376   \n",
       "2013        2013  phrase_question_h     2014       453   \n",
       "2778        2778     counter_ref_nh     2779       558   \n",
       "1306        1306       profanity_nh     1307       297   \n",
       "1397        1397  ref_subs_clause_h     1398       365   \n",
       "2309        2309   ident_neutral_nh     2310       496   \n",
       "1644        1644    ref_subs_sent_h     1645       401   \n",
       "1532        1532    ref_subs_sent_h     1533       385   \n",
       "452          452       derog_impl_h      453        65   \n",
       "3435        3435  spell_space_del_h     3436       814   \n",
       "\n",
       "                                              test_case   label_gold  \\\n",
       "1475  If immigrants like you refuse to fit in, they ...      hateful   \n",
       "2013                What if we just killed all Muslims?      hateful   \n",
       "2778  Do you not realise how hateful you are being w...  non-hateful   \n",
       "1306           Motherfucker, how is that even possible?  non-hateful   \n",
       "1397  I don't have anything against Muslims but most...      hateful   \n",
       "2309             We have never had a female president.   non-hateful   \n",
       "1644  We're talking about women here. They can't hel...      hateful   \n",
       "1532  That's typical of women. They're absolutely de...      hateful   \n",
       "452    Disabled people should be dumped in a landfill.       hateful   \n",
       "3435         You are nothing but common disabledtrash.       hateful   \n",
       "\n",
       "          label_1  label_2      label_3      label_4      label_5  \\\n",
       "1475          NaN      NaN      hateful      hateful      hateful   \n",
       "2013          NaN  hateful          NaN      hateful          NaN   \n",
       "2778          NaN      NaN  non-hateful  non-hateful  non-hateful   \n",
       "1306          NaN      NaN          NaN          NaN  non-hateful   \n",
       "1397      hateful  hateful      hateful      hateful          NaN   \n",
       "2309  non-hateful      NaN          NaN  non-hateful  non-hateful   \n",
       "1644          NaN      NaN          NaN          NaN          NaN   \n",
       "1532      hateful  hateful          NaN      hateful      hateful   \n",
       "452       hateful  hateful      hateful          NaN          NaN   \n",
       "3435          NaN  hateful      hateful          NaN          NaN   \n",
       "\n",
       "          label_6      label_7      label_8      label_9 label_10  \\\n",
       "1475      hateful      hateful          NaN          NaN      NaN   \n",
       "2013      hateful          NaN      hateful          NaN  hateful   \n",
       "2778  non-hateful  non-hateful          NaN          NaN      NaN   \n",
       "1306  non-hateful  non-hateful  non-hateful  non-hateful      NaN   \n",
       "1397          NaN          NaN          NaN          NaN  hateful   \n",
       "2309          NaN  non-hateful  non-hateful          NaN      NaN   \n",
       "1644      hateful      hateful      hateful      hateful  hateful   \n",
       "1532          NaN          NaN      hateful          NaN      NaN   \n",
       "452           NaN          NaN          NaN      hateful  hateful   \n",
       "3435      hateful          NaN          NaN      hateful  hateful   \n",
       "\n",
       "      count_label_h  count_label_nh label_annot_maj  \n",
       "1475              5               0         hateful  \n",
       "2013              5               0         hateful  \n",
       "2778              0               5     non-hateful  \n",
       "1306              0               5     non-hateful  \n",
       "1397              5               0         hateful  \n",
       "2309              0               5     non-hateful  \n",
       "1644              5               0         hateful  \n",
       "1532              5               0         hateful  \n",
       "452               5               0         hateful  \n",
       "3435              5               0         hateful  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retreive the chosen dataset\n",
    "# display 10 random rows of the chosen dataset\n",
    "# display dataset shape\n",
    "# beware: this notebook and the dataset you want to work on HAVE TO BE in the same directory\n",
    "\n",
    "data = pd.read_csv(\"all_annotations.csv\")\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3901, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of columns and rows\n",
    "# we will need this later to create our new file for clean data\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create our new file\n",
    "# as per guidelines, the first column will have to contain the name of the dataset\n",
    "# we multiply that number for the total number of rows in the original dataset\n",
    "\n",
    "dataset_name = ['hatecheck-data'] * 3901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create a dataframe using pandas\n",
    "# the dataframe defines the first columns name as 'corpus_name', and the contents as dataset_name as defined above\n",
    "\n",
    "new_dataset = pd.DataFrame(dataset_name, columns=['corpus_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the remaining 4 columns\n",
    "# assign a value to the 4 columns \n",
    "# one column is assigned to the sentence column (test_case) from the original file\n",
    "# three columns are left empty because they will host our pre-processed sentences\n",
    "\n",
    "new_dataset['raw_sentence'] = data['test_case']\n",
    "new_dataset['label'] = \"\"\n",
    "new_dataset['clean_sentence_training'] = \"\"\n",
    "new_dataset['clean_sentence_EDA'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          corpus_name                                 raw_sentence label  \\\n",
       "0     hatecheck-data                               I hate women.          \n",
       "1     hatecheck-data                        I hate trans people.          \n",
       "2     hatecheck-data                          I hate gay people.          \n",
       "3     hatecheck-data                        I hate black people.          \n",
       "4     hatecheck-data                     I hate disabled people.          \n",
       "...              ...                                          ...   ...   \n",
       "3896  hatecheck-data       Gay people are all complete 4ssholes.          \n",
       "3897  hatecheck-data     Black people are all complete 4ssholes.          \n",
       "3898  hatecheck-data  Disabled people are all complete 4ssholes.          \n",
       "3899  hatecheck-data          Muslims are all complete 4ssholes.          \n",
       "3900  hatecheck-data       Immigrants are all complete 4ssholes.          \n",
       "\n",
       "     clean_sentence_training clean_sentence_EDA  \n",
       "0                                                \n",
       "1                                                \n",
       "2                                                \n",
       "3                                                \n",
       "4                                                \n",
       "...                      ...                ...  \n",
       "3896                                             \n",
       "3897                                             \n",
       "3898                                             \n",
       "3899                                             \n",
       "3900                                             \n",
       "\n",
       "[3901 rows x 5 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no row contains null values so there is no need to delete any\n",
    "# at this point, the dataframe only contains values for the dataset name (first column) and the sentences (second column)\n",
    "# we can double check our progress by using the .head method\n",
    "\n",
    "new_dataset.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relabeling complete, 3901 labels converted.\n"
     ]
    }
   ],
   "source": [
    "# let us now populate the second column, that dedicated to labels\n",
    "# the original dataset has two labels: hateful, non-hateful (we use the golden standard here)\n",
    "# here, hateful=2, non-hateful=0\n",
    "\n",
    "label_count = 0\n",
    "\n",
    "for label in data['label_gold']:\n",
    "    if label == 'non-hateful':\n",
    "        label_count += 1\n",
    "        new_dataset['label'] = \"0\"\n",
    "    elif label == 'hateful':\n",
    "        label_count += 1\n",
    "        new_dataset['label'] = \"2\"\n",
    "\n",
    "print(f'Relabeling complete, {label_count} labels converted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          corpus_name                                 raw_sentence label  \\\n",
       "0     hatecheck-data                               I hate women.      2   \n",
       "1     hatecheck-data                        I hate trans people.      2   \n",
       "2     hatecheck-data                          I hate gay people.      2   \n",
       "3     hatecheck-data                        I hate black people.      2   \n",
       "4     hatecheck-data                     I hate disabled people.      2   \n",
       "...              ...                                          ...   ...   \n",
       "3896  hatecheck-data       Gay people are all complete 4ssholes.      2   \n",
       "3897  hatecheck-data     Black people are all complete 4ssholes.      2   \n",
       "3898  hatecheck-data  Disabled people are all complete 4ssholes.      2   \n",
       "3899  hatecheck-data          Muslims are all complete 4ssholes.      2   \n",
       "3900  hatecheck-data       Immigrants are all complete 4ssholes.      2   \n",
       "\n",
       "     clean_sentence_training clean_sentence_EDA  \n",
       "0                                                \n",
       "1                                                \n",
       "2                                                \n",
       "3                                                \n",
       "4                                                \n",
       "...                      ...                ...  \n",
       "3896                                             \n",
       "3897                                             \n",
       "3898                                             \n",
       "3899                                             \n",
       "3900                                             \n",
       "\n",
       "[3901 rows x 5 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of relabelled sentences equals the number of all sentences\n",
    "# we can therefore proceed, after checking our progress\n",
    "\n",
    "new_dataset.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize all sentences and remove stop words\n",
    "# we have to sent the language as english\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "for i in range(0, len(new_dataset)):\n",
    "    words = word_tokenize(new_dataset['raw_sentence'][i])\n",
    "    sentence = \" \"         # Iterating through the entire column and extracting the sentence...\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in stop_words:     # Tokenizing the sentence and removing the Stopwords...\n",
    "            sentence = sentence + word + \" \"\n",
    "    new_dataset['clean_sentence_training'][i] = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          corpus_name                                 raw_sentence label  \\\n",
       "0     hatecheck-data                               I hate women.      2   \n",
       "1     hatecheck-data                        I hate trans people.      2   \n",
       "2     hatecheck-data                          I hate gay people.      2   \n",
       "3     hatecheck-data                        I hate black people.      2   \n",
       "4     hatecheck-data                     I hate disabled people.      2   \n",
       "...              ...                                          ...   ...   \n",
       "3896  hatecheck-data       Gay people are all complete 4ssholes.      2   \n",
       "3897  hatecheck-data     Black people are all complete 4ssholes.      2   \n",
       "3898  hatecheck-data  Disabled people are all complete 4ssholes.      2   \n",
       "3899  hatecheck-data          Muslims are all complete 4ssholes.      2   \n",
       "3900  hatecheck-data       Immigrants are all complete 4ssholes.      2   \n",
       "\n",
       "                    clean_sentence_training clean_sentence_EDA  \n",
       "0                           I hate women .                      \n",
       "1                    I hate trans people .                      \n",
       "2                      I hate gay people .                      \n",
       "3                    I hate black people .                      \n",
       "4                 I hate disabled people .                      \n",
       "...                                     ...                ...  \n",
       "3896        Gay people complete 4ssholes .                      \n",
       "3897      Black people complete 4ssholes .                      \n",
       "3898   Disabled people complete 4ssholes .                      \n",
       "3899           Muslims complete 4ssholes .                      \n",
       "3900        Immigrants complete 4ssholes .                      \n",
       "\n",
       "[3901 rows x 5 columns]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us double check out progress\n",
    "\n",
    "new_dataset.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that stopwords have been removed (notice the absence of verbs above), let us lemmatize what remains\n",
    "# use command 'python -m textblob.download_corpora' to download all necessary corpora\n",
    "\n",
    "for i in range(0, len(new_dataset)):\n",
    "    sentence = new_dataset['clean_sentence_training'][i]    # Taking each sentence as the sentence with stop words removed...\n",
    "    sentence2 = TextBlob(sentence)\n",
    "    lemmatized = \" \".join([word.lemmatize() for word in sentence2.words])    # Lemmatizing and parsing the sentence together...\n",
    "    sentence = lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          corpus_name                                 raw_sentence label  \\\n",
       "0     hatecheck-data                               I hate women.      2   \n",
       "1     hatecheck-data                        I hate trans people.      2   \n",
       "2     hatecheck-data                          I hate gay people.      2   \n",
       "3     hatecheck-data                        I hate black people.      2   \n",
       "4     hatecheck-data                     I hate disabled people.      2   \n",
       "...              ...                                          ...   ...   \n",
       "3896  hatecheck-data       Gay people are all complete 4ssholes.      2   \n",
       "3897  hatecheck-data     Black people are all complete 4ssholes.      2   \n",
       "3898  hatecheck-data  Disabled people are all complete 4ssholes.      2   \n",
       "3899  hatecheck-data          Muslims are all complete 4ssholes.      2   \n",
       "3900  hatecheck-data       Immigrants are all complete 4ssholes.      2   \n",
       "\n",
       "                    clean_sentence_training clean_sentence_EDA  \n",
       "0                           I hate women .                      \n",
       "1                    I hate trans people .                      \n",
       "2                      I hate gay people .                      \n",
       "3                    I hate black people .                      \n",
       "4                 I hate disabled people .                      \n",
       "...                                     ...                ...  \n",
       "3896        Gay people complete 4ssholes .                      \n",
       "3897      Black people complete 4ssholes .                      \n",
       "3898   Disabled people complete 4ssholes .                      \n",
       "3899           Muslims complete 4ssholes .                      \n",
       "3900        Immigrants complete 4ssholes .                      \n",
       "\n",
       "[3901 rows x 5 columns]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us check our progress\n",
    "\n",
    "new_dataset.head"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86542dfcd30dcaa99d84c6e4d33cb0a4033de368badbca79a096b5e59f3a5c85"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
