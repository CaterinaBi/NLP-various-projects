{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic pre-processing of textual dataset\n",
    "# For EDA and language model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook demonstrates basic pre-processing techniques using the `nltk` and `spaCy` libraries\n",
    "\n",
    "The task is done to prepare datasets of hate speech for use in the Omdena Aswan Local Chapter, 'Detecting Hateful and Offensive Language using NLP', in which I am cooperating and co-leading the pre-processing and EDA tasks with Vishu Kalier.\n",
    "\n",
    "Here, we will be using the hatecheck-data (https://github.com/paul-rottger/hatecheck-data) dataset.\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "I shall complete the task by strictly following the guidelines outlined for the project. These are as follows.\n",
    "\n",
    "### File structure\n",
    "\n",
    "The output of the pre-processing has to be a `.cvs` file. The file has to be organised in 5 columns as follows: \n",
    "| corpus_name | raw_sentence | label | clean_sentence_training | clean_sentence_EDA | \n",
    "\n",
    "### Labels\n",
    "\n",
    "The labels will be:\n",
    "\n",
    "- '2' for RISKY sentences (eg., 'hateful' or 'abusive');\n",
    "- '1' for POTENTIALLY RISKY sentences (e.g., 'offensive)';\n",
    "- '0' for NON RISKY sentences.\n",
    "\n",
    "### Pre-processing\n",
    "\n",
    "The pre-processing for the 'clean_sentence_training' column involves the following steps:\n",
    "\n",
    "1- delete all rows containing null values;\n",
    "\n",
    "2- stopwords removal;\n",
    "\n",
    "3- removal of digits and words containing digits, punctuation and special characters, extra spaces, links;\n",
    "\n",
    "4- lemmatization (NO stemming at it can yield undesirable results).\n",
    "\n",
    "The case of the sentences shoudn't be changed as the distinction between lowercase and uppercase can be meaningful in this context. The pre-processing for the 'clean_sentence_EDA' involves all the steps above, plus the deletion of all emojis (if present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/caterinabonan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "# don't forget to install any library that you don't have in your workspace yet\n",
    "# make sure that the environment you're installing your libraries corresponds to the one you're using to compile your code\n",
    "# note that the downloads form nltk might take a while\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the spaCy standard model for English\n",
    "# use the command 'python -m spacy download en_core_web_lg' if the model isn't already in your machine\n",
    "# note that downloading the model can tale some time\n",
    "# refer to the spaCy documentation if you're working on languages other than English\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>functionality</th>\n",
       "      <th>case_id</th>\n",
       "      <th>templ_id</th>\n",
       "      <th>test_case</th>\n",
       "      <th>label_gold</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "      <th>label_5</th>\n",
       "      <th>label_6</th>\n",
       "      <th>label_7</th>\n",
       "      <th>label_8</th>\n",
       "      <th>label_9</th>\n",
       "      <th>label_10</th>\n",
       "      <th>count_label_h</th>\n",
       "      <th>count_label_nh</th>\n",
       "      <th>label_annot_maj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>3127</td>\n",
       "      <td>spell_char_swap_h</td>\n",
       "      <td>3128</td>\n",
       "      <td>770</td>\n",
       "      <td>Disabled people with any power are a thraet to...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>derog_neg_emote_h</td>\n",
       "      <td>121</td>\n",
       "      <td>18</td>\n",
       "      <td>You and all the other trans people in this cou...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>895</td>\n",
       "      <td>slur_h</td>\n",
       "      <td>896</td>\n",
       "      <td>124</td>\n",
       "      <td>Just another common slut.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>2170</td>\n",
       "      <td>phrase_opinion_h</td>\n",
       "      <td>2171</td>\n",
       "      <td>476</td>\n",
       "      <td>Personally, I think we should just hang all th...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>3246</td>\n",
       "      <td>spell_char_del_h</td>\n",
       "      <td>3247</td>\n",
       "      <td>787</td>\n",
       "      <td>I have so much hatrd for you disabled people.</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>1279</td>\n",
       "      <td>profanity_nh</td>\n",
       "      <td>1280</td>\n",
       "      <td>270</td>\n",
       "      <td>Why the fuck can I not just skip this exam?</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>2863</td>\n",
       "      <td>counter_ref_nh</td>\n",
       "      <td>2864</td>\n",
       "      <td>567</td>\n",
       "      <td>You have to stop calling people muzzies.</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>2592</td>\n",
       "      <td>counter_quote_nh</td>\n",
       "      <td>2593</td>\n",
       "      <td>536</td>\n",
       "      <td>I will not tolerate posts like \"black people a...</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>non-hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>441</td>\n",
       "      <td>derog_impl_h</td>\n",
       "      <td>442</td>\n",
       "      <td>64</td>\n",
       "      <td>That monkey is more intelligent than all of yo...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>1773</td>\n",
       "      <td>negate_pos_h</td>\n",
       "      <td>1774</td>\n",
       "      <td>419</td>\n",
       "      <td>I would never lift a finger to save a black pe...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hateful</td>\n",
       "      <td>hateful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hateful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      functionality  case_id  templ_id  \\\n",
       "3127        3127  spell_char_swap_h     3128       770   \n",
       "120          120  derog_neg_emote_h      121        18   \n",
       "895          895             slur_h      896       124   \n",
       "2170        2170   phrase_opinion_h     2171       476   \n",
       "3246        3246   spell_char_del_h     3247       787   \n",
       "1279        1279       profanity_nh     1280       270   \n",
       "2863        2863     counter_ref_nh     2864       567   \n",
       "2592        2592   counter_quote_nh     2593       536   \n",
       "441          441       derog_impl_h      442        64   \n",
       "1773        1773       negate_pos_h     1774       419   \n",
       "\n",
       "                                              test_case   label_gold  \\\n",
       "3127  Disabled people with any power are a thraet to...      hateful   \n",
       "120   You and all the other trans people in this cou...      hateful   \n",
       "895                          Just another common slut.       hateful   \n",
       "2170  Personally, I think we should just hang all th...      hateful   \n",
       "3246     I have so much hatrd for you disabled people.       hateful   \n",
       "1279        Why the fuck can I not just skip this exam?  non-hateful   \n",
       "2863          You have to stop calling people muzzies.   non-hateful   \n",
       "2592  I will not tolerate posts like \"black people a...  non-hateful   \n",
       "441   That monkey is more intelligent than all of yo...      hateful   \n",
       "1773  I would never lift a finger to save a black pe...      hateful   \n",
       "\n",
       "          label_1      label_2      label_3      label_4      label_5  \\\n",
       "3127          NaN      hateful          NaN      hateful          NaN   \n",
       "120       hateful          NaN          NaN      hateful          NaN   \n",
       "895           NaN          NaN          NaN          NaN          NaN   \n",
       "2170      hateful          NaN      hateful          NaN      hateful   \n",
       "3246          NaN          NaN          NaN          NaN          NaN   \n",
       "1279  non-hateful  non-hateful  non-hateful  non-hateful          NaN   \n",
       "2863  non-hateful  non-hateful          NaN          NaN  non-hateful   \n",
       "2592  non-hateful  non-hateful          NaN  non-hateful  non-hateful   \n",
       "441       hateful          NaN      hateful          NaN      hateful   \n",
       "1773      hateful      hateful          NaN          NaN      hateful   \n",
       "\n",
       "      label_6  label_7      label_8      label_9     label_10  count_label_h  \\\n",
       "3127  hateful      NaN      hateful          NaN      hateful              5   \n",
       "120       NaN  hateful      hateful          NaN      hateful              5   \n",
       "895   hateful  hateful      hateful      hateful      hateful              5   \n",
       "2170      NaN  hateful          NaN      hateful          NaN              5   \n",
       "3246  hateful  hateful      hateful      hateful      hateful              5   \n",
       "1279      NaN      NaN          NaN          NaN  non-hateful              0   \n",
       "2863      NaN      NaN  non-hateful  non-hateful          NaN              0   \n",
       "2592      NaN      NaN  non-hateful          NaN          NaN              0   \n",
       "441       NaN  hateful          NaN      hateful          NaN              5   \n",
       "1773      NaN      NaN      hateful      hateful          NaN              5   \n",
       "\n",
       "      count_label_nh label_annot_maj  \n",
       "3127               0         hateful  \n",
       "120                0         hateful  \n",
       "895                0         hateful  \n",
       "2170               0         hateful  \n",
       "3246               0         hateful  \n",
       "1279               5     non-hateful  \n",
       "2863               5     non-hateful  \n",
       "2592               5     non-hateful  \n",
       "441                0         hateful  \n",
       "1773               0         hateful  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retreive the chosen dataset\n",
    "# display 10 random rows of the chosen dataset\n",
    "# display dataset shape\n",
    "# beware: this notebook and the dataset you want to work on HAVE TO BE in the same directory\n",
    "\n",
    "data = pd.read_csv(\"all_annotations.csv\")\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3901, 19)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of columns and rows\n",
    "# we will need this later to create our new file for clean data\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create our new file\n",
    "# as per guidelines, the first column will have to contain the name of the dataset\n",
    "# we multiply that number for the total number of rows in the original dataset\n",
    "\n",
    "dataset_name = ['hatecheck-data'] * 3901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataFrame.__init__() got an unexpected keyword argument 'column'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# now we create a dataframe using pandas\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# the dataframe defines the first columns name as 'corpus_name', and the contents as dataset_name as defined above\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m new_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcorpus_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: DataFrame.__init__() got an unexpected keyword argument 'column'"
     ]
    }
   ],
   "source": [
    "# now we create a dataframe using pandas\n",
    "# the dataframe defines the first columns name as 'corpus_name', and the contents as dataset_name as defined above\n",
    "\n",
    "new_dataset = pd.DataFrame(dataset_name, columns=['corpus_name'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86542dfcd30dcaa99d84c6e4d33cb0a4033de368badbca79a096b5e59f3a5c85"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
