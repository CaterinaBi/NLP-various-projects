{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Techniques\n",
    "\n",
    "## Basic techniques: From tokenization to lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tika import parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of dataset\n",
    "\n",
    "I will work on an online hate speech corpus collected from Reddit, 'A Benchmark Dataset for Learning to Intervene in Online Hate Speech' (https://github.com/jing-qian/A-Benchmark-Dataset-for-Learning-to-Intervene-in-Online-Hate-Speech), and on a random nutrition book whose .pdf version was freely distributed on-line, 'Fundamentals of Foods, Nutrition and Diet Therapy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hate_speech_idx</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>1. e9721xg\\n2. \\te974az5\\n3. \\t\\te975los\\n4. \\...</td>\n",
       "      <td>1. Reading this made me feel dead inside. I ca...</td>\n",
       "      <td>[1, 2, 6]</td>\n",
       "      <td>[\"This seems mostly like joking around, the la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>1. e981ap7\\n2. \\te983nn4\\n</td>\n",
       "      <td>1. I mean it's not complicated—some of the fag...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['avoid words like fag and retards as they are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>1. dxacc1b\\n2. \\tdxacznd\\n3. \\t\\tdxamswu\\n</td>\n",
       "      <td>1. Most women have no empathy for men and boys...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[\"Using offensive language doesn't make anyone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>1. dxch9p1\\n2. \\tdxl48mj\\n</td>\n",
       "      <td>1. Dude was chill as fuck. That's how you deal...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[\"I don't see a reason why it's okay to attack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>1. e89237t\\n2. \\te892wcq\\n3. \\t\\te893me1\\n4. \\...</td>\n",
       "      <td>1. if i know you're a gay tranny, *and i never...</td>\n",
       "      <td>[1, 2, 11]</td>\n",
       "      <td>['This speech attacks transgender people.', \"W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>1. e8ewapd\\n2. \\te8fozf0\\n</td>\n",
       "      <td>1. But..but..Orange man bad \\n2. \\tDumbass red...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>['homophobic slurs are offensive and hurtful a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>1. e6z49si\\n2. \\te6zdegp\\n3. \\t\\te6zhza4\\n4. \\...</td>\n",
       "      <td>1. She's underage, with open alcohol, yelling ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>1. e5lmksp\\n</td>\n",
       "      <td>1. Okay, would you prefer we call you a dick, ...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['Using the \"c---\" term is offensive and shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>1. e0n23lx\\n</td>\n",
       "      <td>1. My 23 year old daughter thinks that each of...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['Using the slur here hurts and demeans women,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4464</th>\n",
       "      <td>1. dz7hty7\\n</td>\n",
       "      <td>1. Surely in a case like this, we need to adap...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[\"Sounds like you're speaking from experience....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  \\\n",
       "1794  1. e9721xg\\n2. \\te974az5\\n3. \\t\\te975los\\n4. \\...   \n",
       "4773                         1. e981ap7\\n2. \\te983nn4\\n   \n",
       "2684         1. dxacc1b\\n2. \\tdxacznd\\n3. \\t\\tdxamswu\\n   \n",
       "2006                         1. dxch9p1\\n2. \\tdxl48mj\\n   \n",
       "3316  1. e89237t\\n2. \\te892wcq\\n3. \\t\\te893me1\\n4. \\...   \n",
       "3016                         1. e8ewapd\\n2. \\te8fozf0\\n   \n",
       "592   1. e6z49si\\n2. \\te6zdegp\\n3. \\t\\te6zhza4\\n4. \\...   \n",
       "3228                                       1. e5lmksp\\n   \n",
       "2260                                       1. e0n23lx\\n   \n",
       "4464                                       1. dz7hty7\\n   \n",
       "\n",
       "                                                   text hate_speech_idx  \\\n",
       "1794  1. Reading this made me feel dead inside. I ca...       [1, 2, 6]   \n",
       "4773  1. I mean it's not complicated—some of the fag...             [1]   \n",
       "2684  1. Most women have no empathy for men and boys...             [3]   \n",
       "2006  1. Dude was chill as fuck. That's how you deal...             [1]   \n",
       "3316  1. if i know you're a gay tranny, *and i never...      [1, 2, 11]   \n",
       "3016  1. But..but..Orange man bad \\n2. \\tDumbass red...             [2]   \n",
       "592   1. She's underage, with open alcohol, yelling ...             NaN   \n",
       "3228  1. Okay, would you prefer we call you a dick, ...             [1]   \n",
       "2260  1. My 23 year old daughter thinks that each of...             [1]   \n",
       "4464  1. Surely in a case like this, we need to adap...             [1]   \n",
       "\n",
       "                                               response  \n",
       "1794  [\"This seems mostly like joking around, the la...  \n",
       "4773  ['avoid words like fag and retards as they are...  \n",
       "2684  [\"Using offensive language doesn't make anyone...  \n",
       "2006  [\"I don't see a reason why it's okay to attack...  \n",
       "3316  ['This speech attacks transgender people.', \"W...  \n",
       "3016  ['homophobic slurs are offensive and hurtful a...  \n",
       "592                                                 NaN  \n",
       "3228  ['Using the \"c---\" term is offensive and shoul...  \n",
       "2260  ['Using the slur here hurts and demeans women,...  \n",
       "4464  [\"Sounds like you're speaking from experience....  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first dataset (.csv file)\n",
    "\n",
    "dataset1 = pd.read_csv('reddit.csv')\n",
    "dataset1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second dataset (.pdf file)\n",
    "\n",
    "dataset2 = parser.from_file('fundamentals-of-foodnutrition-and-diet-therapy.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Process of segmenting text into sentences and then tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading spacy's statistical model for tokenization\n",
    "# this one is the smallest English model offered by the library\n",
    "# this need to be downloaded using the command python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86542dfcd30dcaa99d84c6e4d33cb0a4033de368badbca79a096b5e59f3a5c85"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
